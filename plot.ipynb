{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import patches\n",
    "from operator import add\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.read_csv('data/all_results.csv')\n",
    "df_PL_all = df[(df['dataset'] == 'MCQs_PL_all')].copy()\n",
    "\n",
    "# count the number of models in the df_PL_all dataframe\n",
    "length = len(df_PL_all)\n",
    "print(length)\n",
    "\n",
    "# reindex the models ids of the df_PL_all dataframe\n",
    "df_PL_all['id'] = [i for i in range(length)]\n",
    "\n",
    "# add accuracy column to the df_PL_all dataframe\n",
    "\"\"\"\n",
    "Functional Programming: 1\n",
    "Algorithms: 2\n",
    "Fundations: 3\n",
    "Abstract Machines: 4\n",
    "Memory Management: 5\n",
    "Names and the Environment: 7\n",
    "Describing a Programming Language: 8\n",
    "Object-Oriented Paradigm: 11\n",
    "Control Structure: 11\n",
    "Structuring Data: 30\n",
    "Programming Languages: 80\n",
    "\n",
    "functional_programming, algorithms, fundations, abstract_machines, memory_management, names_and_the_environment, describing_a_programming_language, object_oriented_paradigm, control_structure, structuring_data\n",
    "\"\"\"\n",
    "df_PL_all['accuracy'] = round(df_PL_all['correct_responses'] / 162 * 100)\n",
    "df_PL_all['functional_programming_accuracy'] = round(df_PL_all['functional_programming'] / 1 * 100)\n",
    "df_PL_all['algorithms_accuracy'] = round(df_PL_all['algorithms'] / 2 * 100)\n",
    "df_PL_all['fundations_accuracy'] = round(df_PL_all['fundations'] / 3 * 100)\n",
    "df_PL_all['abstract_machines_accuracy'] = round(df_PL_all['abstract_machines'] / 4 * 100)\n",
    "df_PL_all['memory_management_accuracy'] = round(df_PL_all['memory_management'] / 5 * 100)\n",
    "df_PL_all['names_and_the_environment_accuracy'] = round(df_PL_all['names_and_the_environment'] / 7 * 100)\n",
    "df_PL_all['describing_a_programming_language_accuracy'] = round(df_PL_all['describing_a_programming_language'] / 8 * 100)\n",
    "df_PL_all['object_oriented_paradigm_accuracy'] = round(df_PL_all['object_oriented_paradigm'] / 11 * 100)\n",
    "df_PL_all['control_structure_accuracy'] = round(df_PL_all['control_structure'] / 11 * 100)\n",
    "df_PL_all['structuring_data_accuracy'] = round(df_PL_all['structuring_data'] / 30 * 100)\n",
    "df_PL_all['programming_languages_accuracy'] = round(df_PL_all['programming_languages'] / 80 * 100)\n",
    "\n",
    "# print head of the df_PL_all dataframe with all columns\n",
    "df_PL_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of total rows that have a the mode column equal to finetuned and the dataset column equal to MCQs_PL_all\n",
    "df_PL_all_finetuned = df_PL_all[(df_PL_all['mode'] == 'finetuned') & (df_PL_all['dataset'] == 'MCQs_PL_all')].copy()\n",
    "df_PL_all_finetuned_length = len(df_PL_all_finetuned)\n",
    "print(\"df_PL_all_finetuned_length: \", df_PL_all_finetuned_length)\n",
    "# get the number of total rows that have a the mode column equal to finetuned and the dataset column equal to MCQs_PL_all with model equal to Llama-2-7b-chat-hf\n",
    "df_PL_all_finetuned_Llama_2_7b_chat_hf = df_PL_all[(df_PL_all['mode'] == 'finetuned') & (df_PL_all['dataset'] == 'MCQs_PL_all') & (df_PL_all['model'] == 'Llama-2-7b-chat-hf')].copy()\n",
    "df_PL_all_finetuned_Llama_2_7b_chat_hf_length = len(df_PL_all_finetuned_Llama_2_7b_chat_hf)\n",
    "print(\"df_PL_all_finetuned_Llama_2_7b_chat_hf_length: \", df_PL_all_finetuned_Llama_2_7b_chat_hf_length)\n",
    "# get the number of total rows that have a the mode column equal to finetuned and the dataset column equal to MCQs_PL_all with model equal to Llama-2-13b-chat-hf\n",
    "df_PL_all_finetuned_Llama_2_13b_chat_hf = df_PL_all[(df_PL_all['mode'] == 'finetuned') & (df_PL_all['dataset'] == 'MCQs_PL_all') & (df_PL_all['model'] == 'Llama-2-13b-chat-hf')].copy()\n",
    "df_PL_all_finetuned_Llama_2_13b_chat_hf_length = len(df_PL_all_finetuned_Llama_2_13b_chat_hf)\n",
    "print(\"df_PL_all_finetuned_Llama_2_13b_chat_hf_length: \", df_PL_all_finetuned_Llama_2_13b_chat_hf_length)\n",
    "# get the number of total rows that have a the mode column equal to finetuned and the dataset column equal to MCQs_PL_all with model equal to Llama-2-7b-chat-hf and the accuracy column less than 35\n",
    "df_PL_all_finetuned_Llama_2_7b_chat_hf_accuracy_less_than_35 = df_PL_all[(df_PL_all['mode'] == 'finetuned') & (df_PL_all['dataset'] == 'MCQs_PL_all') & (df_PL_all['model'] == 'Llama-2-7b-chat-hf') & (df_PL_all['accuracy'] < 35)].copy()\n",
    "df_PL_all_finetuned_Llama_2_7b_chat_hf_accuracy_less_than_35_length = len(df_PL_all_finetuned_Llama_2_7b_chat_hf_accuracy_less_than_35)\n",
    "print(\"df_PL_all_finetuned_Llama_2_7b_chat_hf_accuracy_less_than_35_length: \", df_PL_all_finetuned_Llama_2_7b_chat_hf_accuracy_less_than_35_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set palette\n",
    "palette = sns.color_palette(\"husl\", 8)\n",
    "sns.set_palette(palette)\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_general_info(model, models, z, df_model, ax, partition, comparing_partitions, subtitle=''):\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "\n",
    "    count_questions = 162\n",
    "    if comparing_partitions is not None:\n",
    "        # add values for the comparing partitions\n",
    "        y_values = []\n",
    "        count_questions = 0\n",
    "        for i, comparing_partition in enumerate(comparing_partitions):\n",
    "            tmp_values = df_model[comparing_partition]\n",
    "            # make tmp_values a list\n",
    "            tmp_values = tmp_values.tolist()\n",
    "            # add the values of the previous partitions\n",
    "            if i > 0:\n",
    "                y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "            else:\n",
    "                y_values = tmp_values\n",
    "            count_questions += df_model['num_' + comparing_partition].min()\n",
    "        y_values = [round(y_value / count_questions * 100) for y_value in y_values]\n",
    "        sns.scatterplot(y=y_values, x=df_model['id'], ax=ax, color='black')\n",
    "    else:\n",
    "        sns.scatterplot(y=df_model[partition], x=df_model['id'], ax=ax, color='black')\n",
    "        if partition != 'accuracy':\n",
    "            count_questions = df_model['num_' + partition].max()\n",
    "\n",
    "    # add a vertical line to separate the quantized models from the base ones\n",
    "    min_id = df_model[df_model['quantized'] == 'quantized']['id'].min()\n",
    "    ax.axvline(min_id, color='black', linestyle='-', linewidth=1)\n",
    "    # add two text in the two parts of the plot to explain the quantized models\n",
    "    ax.text(0, 70, 'Base', color='black')\n",
    "    ax.text(min_id+5, 70, 'Quantized', color='black')\n",
    "\n",
    "    \"\"\" # Add points for pretrained models\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'pretrained')].copy()\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "    accuracy = df_model[partition]\n",
    "    pretrained_accuracy = accuracy.max()\n",
    "    pretrained_quantized_accuracy = accuracy.min() \"\"\"\n",
    "\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'pretrained')].copy()\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "    if comparing_partitions is not None:\n",
    "        y_values = []\n",
    "        for i, comparing_partition in enumerate(comparing_partitions):\n",
    "            tmp_values = df_model[comparing_partition]\n",
    "            tmp_values = tmp_values.tolist()\n",
    "            if i > 0:\n",
    "                y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "            else:\n",
    "                y_values = tmp_values\n",
    "        y_values = [round(y_value / count_questions * 100) for y_value in y_values]\n",
    "        pretrained_accuracy = max(y_values)\n",
    "        pretrained_quantized_accuracy = min(y_values)\n",
    "    \n",
    "    \"\"\" # Add points for next model version\n",
    "    model_to_compare = models[z+1]\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model_to_compare) & (df_PL_all['mode'] == 'pretrained')].copy()\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "    accuracy = df_model[partition]\n",
    "    pretrained_big_accuracy = accuracy.max() \"\"\"\n",
    "\n",
    "    model_to_compare = models[z+1]\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model_to_compare) & (df_PL_all['mode'] == 'pretrained')].copy()\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "    if comparing_partitions is not None:\n",
    "        y_values = []\n",
    "        for i, comparing_partition in enumerate(comparing_partitions):\n",
    "            tmp_values = df_model[comparing_partition]\n",
    "            tmp_values = tmp_values.tolist()\n",
    "            if i > 0:\n",
    "                y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "            else:\n",
    "                y_values = tmp_values\n",
    "        y_values = [round(y_value / count_questions * 100) for y_value in y_values]\n",
    "        pretrained_big_accuracy = max(y_values)\n",
    "\n",
    "    if pretrained_accuracy != pretrained_quantized_accuracy and pretrained_accuracy != pretrained_big_accuracy and pretrained_quantized_accuracy != pretrained_big_accuracy:\n",
    "        hline_color = sns.color_palette(palette).as_hex()[0]\n",
    "        ax.axhline(pretrained_accuracy, linestyle='-', label='pretrained', color=hline_color)\n",
    "        hline_color = sns.color_palette(palette).as_hex()[3]\n",
    "        ax.axhline(pretrained_quantized_accuracy, linestyle='-', label='pretrained quantized', color=hline_color)\n",
    "        hline_color = sns.color_palette(palette).as_hex()[6]\n",
    "        ax.axhline(pretrained_big_accuracy, linestyle='-', label='pretrained bigger version (13B for 7B, 70B for 13B)', color=hline_color)\n",
    "    elif pretrained_accuracy == pretrained_quantized_accuracy and pretrained_accuracy == pretrained_big_accuracy:\n",
    "        hline_color = sns.color_palette(palette).as_hex()[5]\n",
    "        ax.axhline(pretrained_big_accuracy, linestyle='-', label='pretrained (base and quantized) and pretrained bigger version (13B for 7B, 70B for 13B)', color=hline_color)\n",
    "    elif pretrained_accuracy == pretrained_quantized_accuracy and pretrained_accuracy != pretrained_big_accuracy:\n",
    "        hline_color = sns.color_palette(palette).as_hex()[4]\n",
    "        ax.axhline(pretrained_accuracy, linestyle='-', label='pretrained (base and quantized)', color=hline_color)\n",
    "        hline_color = sns.color_palette(palette).as_hex()[6]\n",
    "        ax.axhline(pretrained_big_accuracy, linestyle='-', label='pretrained bigger version (13B for 7B, 70B for 13B)', color=hline_color)\n",
    "    elif pretrained_accuracy == pretrained_big_accuracy and pretrained_accuracy != pretrained_quantized_accuracy:\n",
    "        hline_color = sns.color_palette(palette).as_hex()[7]\n",
    "        ax.axhline(pretrained_accuracy, linestyle='-', label='pretrained base and pretrained bigger version (13B for 7B, 70B for 13B)', color=hline_color)\n",
    "        hline_color = sns.color_palette(palette).as_hex()[3]\n",
    "        ax.axhline(pretrained_quantized_accuracy, linestyle='-', label='pretrained quantized', color=hline_color)\n",
    "    elif pretrained_quantized_accuracy == pretrained_big_accuracy and pretrained_quantized_accuracy != pretrained_accuracy:\n",
    "        hline_color = sns.color_palette(palette).as_hex()[0]\n",
    "        ax.axhline(pretrained_accuracy, linestyle='-', label='pretrained', color=hline_color)\n",
    "        hline_color = sns.color_palette(palette).as_hex()[1]\n",
    "        ax.axhline(pretrained_quantized_accuracy, linestyle='-', label='pretrained quantized and pretrained bigger version (13B for 7B, 70B for 13B)', color=hline_color) \n",
    "    \n",
    "    \"\"\" # Plot confidence interval\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'finetuned')].copy()\n",
    "    max_value = df_model[partition].max()\n",
    "    min_value = df_model[partition].min()\n",
    "    ax.axhline(max_value, color='grey', linestyle='--', label='confidence interval')\n",
    "    ax.axhline(min_value, color='grey', linestyle='--') \"\"\"\n",
    "\n",
    "    df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'finetuned')].copy()\n",
    "    length = len(df_model)\n",
    "    df_model['id'] = [i for i in range(length)]\n",
    "    if comparing_partitions is not None:\n",
    "        y_values = []\n",
    "        for i, comparing_partition in enumerate(comparing_partitions):\n",
    "            tmp_values = df_model[comparing_partition]\n",
    "            tmp_values = tmp_values.tolist()\n",
    "            if i > 0:\n",
    "                y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "            else:\n",
    "                y_values = tmp_values\n",
    "        y_values = [round(y_value / count_questions * 100) for y_value in y_values]\n",
    "        max_value = max(y_values)\n",
    "        min_value = min(y_values)\n",
    "    ax.axhline(max_value, color='grey', linestyle='--', label='confidence interval')\n",
    "    ax.axhline(min_value, color='grey', linestyle='--')\n",
    "\n",
    "    # Add labels\n",
    "    # ax.set_ylabel('Number of MCQs correctly answered by the model')\n",
    "    ax.set_ylabel('Accuracy (#MCQs = ' + str(count_questions) + ')' )\n",
    "    ax.set_xlabel(f'Finetuned {model.replace(\"Llama-2-\", \"\").replace(\"b-chat-hf\", \"B\")} models')\n",
    "\n",
    "    # Set ticks\n",
    "    ax.set_xticks([])\n",
    "    y_ticks = np.arange(0, 110, 10)\n",
    "    y_ticks_labels = [str(i)+'%' for i in y_ticks]\n",
    "    # replace last two elements with empty strings\n",
    "    #y_ticks_labels[-2:] = ['...', '100%']\n",
    "    ax.set_yticks(ticks=y_ticks, labels=y_ticks_labels)\n",
    "\n",
    "    # Set title\n",
    "    if subtitle=='':\n",
    "        ax.set_title(model.replace('Llama-2-', '').replace('b-chat-hf', 'B') + ' models ')\n",
    "    else:\n",
    "        ax.set_title(model.replace('Llama-2-', '').replace('b-chat-hf', 'B') + ' models ' + str(subtitle))\n",
    "\n",
    "def plot_accuracy(axs, partition, comparing_partitions=None, col=None, col_values=None):\n",
    "    models = ['Llama-2-7b-chat-hf', 'Llama-2-13b-chat-hf', 'Llama-2-70b-chat-hf']\n",
    "    for i, model in enumerate(models[:-1].copy()):\n",
    "        # plot the distribution of accuracy for each model: 'Llama-2-7b-chat-hf', 'Llama-2-13b-chat-hf'\n",
    "        if col:\n",
    "            for j, col_value in enumerate(col_values):\n",
    "                df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'finetuned') & (df_PL_all[col] == col_value)].copy()\n",
    "                if not df_model.empty:\n",
    "                    add_general_info(model, models, i, df_model, axs[i][j], partition, comparing_partitions, subtitle=col_value)\n",
    "        else:\n",
    "            df_model = df_PL_all[(df_PL_all['model'] == model) & (df_PL_all['mode'] == 'finetuned')].copy()\n",
    "            add_general_info(model, models, i, df_model, axs[i], partition, comparing_partitions)\n",
    "\n",
    "def plot(save_file_name, figsize=(10, 7), partition='accuracy', comparing_partitions=None, col=None, col_values=None):\n",
    "    axs = None\n",
    "    if col:\n",
    "        fig, axs = plt.subplots(2, len(col_values), figsize=figsize, sharey=True)\n",
    "        plot_accuracy(axs=axs, partition=partition, comparing_partitions=comparing_partitions, col=col, col_values=col_values)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(2, 1, figsize=figsize, sharey=True)\n",
    "        plot_accuracy(axs=axs, partition=partition, comparing_partitions=comparing_partitions)\n",
    "\n",
    "    # Set title of figure\n",
    "    if (save_file_name == 'data/plots/All_dataset/'):\n",
    "        fig.suptitle('Accuracy of MCQs correctly answered by different versions of finetuned models')\n",
    "    else:\n",
    "        title_string = save_file_name.split('/')[-2]\n",
    "        #fig.suptitle('Accuracy of MCQs correctly answered by different versions of finetuned models - Partition ' + title_string)\n",
    "\n",
    "    # Add legend\n",
    "    # hline_colors = [sns.color_palette(palette).as_hex()[i] for i in [0, 3, 6, 5, 4, 7, 1]]\n",
    "    hline_colors = [sns.color_palette(palette).as_hex()[i] for i in [0, 3, 6, 4]]\n",
    "    # labels = ['pretrained', 'pretrained quantized', 'pretrained bigger version (13B for 7B, 70B for 13B)', 'pretrained (base and quantized) and pretrained bigger version (13B for 7B, 70B for 13B)', 'pretrained (base and quantized)', 'pretrained base and pretrained bigger version (13B for 7B, 70B for 13B)', 'pretrained quantized and pretrained bigger version (13B for 7B, 70B for 13B)']\n",
    "    labels = ['pretrained', 'pretrained quantized', 'pretrained bigger version (13B for 7B, 70B for 13B)', 'pretrained (base and quantized)']\n",
    "    # labels = ['pretrained', 'pretrained quantized', 'pretrained bigger version (13B for 7B, 70B for 13B)']\n",
    "    patches_ = [patches.Patch(color=x, label=y) for x, y in zip(hline_colors, labels)]\n",
    "    fig.legend(handles=patches_, loc='outside upper right', bbox_to_anchor=(0.9, 1.07), ncol=1)\n",
    "\n",
    "    # Save the plot with tight layout\n",
    "    plt.savefig(save_file_name, bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_plot(file_name_dir, tmp_partition, tmp_comparing_partitions):\n",
    "    tmp_file_name_dir = file_name_dir + tmp_partition\n",
    "    if not os.path.exists(tmp_file_name_dir):\n",
    "        os.makedirs(tmp_file_name_dir)\n",
    "    plot(tmp_file_name_dir + 'general.png', figsize=(5, 7), comparing_partitions=tmp_comparing_partitions)\n",
    "    plot(tmp_file_name_dir + 'finetuning_dataset.png', figsize=(12, 7), comparing_partitions=tmp_comparing_partitions, col='finetuning_dataset', col_values=['book_dataset', 'book_3chapters_dataset', 'book_1chapter_dataset'])\n",
    "    plot(tmp_file_name_dir + 'finetuning_quantized.png', comparing_partitions=tmp_comparing_partitions, col='finetuning_quantized', col_values=['f_base', 'f_quantized'])\n",
    "    plot(tmp_file_name_dir + 'learning_rate.png', comparing_partitions=tmp_comparing_partitions, col='lr', col_values=[0.001, 0.0001])\n",
    "    plot(tmp_file_name_dir + 'batch_size.png', figsize=(15, 7), comparing_partitions=tmp_comparing_partitions, col='bs', col_values=[16, 32, 64, 128])\n",
    "    plot(tmp_file_name_dir + 'iterations.png', figsize=(16, 7), comparing_partitions=tmp_comparing_partitions, col='mi', col_values=[100, 500, 1000, 1500, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'All_dataset/'\n",
    "file_name_dir = 'data/plots/' + dir_name\n",
    "partitions = ['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data', 'programming_languages']\n",
    "partition_plot(file_name_dir, '/All_dataset/', partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'PL_vs_all/'\n",
    "file_name_dir = 'data/plots/' + dir_name\n",
    "partitions = ['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data', 'programming_languages']\n",
    "first_comparing_partitions = ['programming_languages']\n",
    "second_comparing_partitions = [item for item in partitions if item not in first_comparing_partitions]\n",
    "partition_plot(file_name_dir, '/PL/', first_comparing_partitions)\n",
    "partition_plot(file_name_dir, '/all/', second_comparing_partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'SDandOOP_vs_all/'\n",
    "file_name_dir = 'data/plots/' + dir_name\n",
    "partitions = ['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data', 'programming_languages']\n",
    "first_comparing_partitions = ['structuring_data', 'object_oriented_paradigm']\n",
    "second_comparing_partitions = [item for item in partitions if item not in first_comparing_partitions]\n",
    "partition_plot(file_name_dir, '/SDandOOP/', first_comparing_partitions)\n",
    "partition_plot(file_name_dir, '/all/', second_comparing_partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'SD_vs_all/'\n",
    "file_name_dir = 'data/plots/' + dir_name\n",
    "partitions = ['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data', 'programming_languages']\n",
    "first_comparing_partitions = ['structuring_data']\n",
    "second_comparing_partitions = [item for item in partitions if item not in first_comparing_partitions]\n",
    "partition_plot(file_name_dir, '/SD/', first_comparing_partitions)\n",
    "partition_plot(file_name_dir, '/all/', second_comparing_partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PL_all = df_PL_all[((df_PL_all['mode'] == 'finetuned') & (df_PL_all['dataset'] == 'MCQs_PL_all'))].copy()\n",
    "# plot the correlation between dataframe columns=[mode, model, quantized, dataset, temperature, finetuning_dataset, finetuning_quantized, lr, bs, mbs, mi] over column correct_responses\n",
    "# add int columns to df_PL_all dataframe\n",
    "# if model == 'Llama-2-7b-chat-hf' then model_int = 0 elif model == 'Llama-2-13b-chat-hf' then model_int = 1 else model_int = 2\n",
    "df_PL_all['model_int'] = None\n",
    "for i, model in enumerate(df_PL_all['model']):\n",
    "    if model == 'Llama-2-7b-chat-hf':\n",
    "        df_PL_all['model_int'][i] = 0\n",
    "    elif model == 'Llama-2-13b-chat-hf':\n",
    "        df_PL_all['model_int'][i] = 1\n",
    "    else:\n",
    "        df_PL_all['model_int'][i] = 2\n",
    "# if quantized == 'quantized' then quantized_int = 1 else quantized_int = 0\n",
    "df_PL_all['quantized_int'] = None\n",
    "for i, quantized in enumerate(df_PL_all['quantized']):\n",
    "    if quantized == 'quantized':\n",
    "        df_PL_all['quantized_int'][i] = 1\n",
    "    else:\n",
    "        df_PL_all['quantized_int'][i] = 0\n",
    "# if finetuning_dataset == 'book_dataset' then finetuning_dataset_int = 0 elif finetuning_dataset == 'book_3chapters_dataset' then finetuning_dataset_int = 1 else finetuning_dataset_int = 2\n",
    "df_PL_all['finetuning_dataset_int'] = None\n",
    "for i, finetuning_dataset in enumerate(df_PL_all['finetuning_dataset']):\n",
    "    if finetuning_dataset == 'book_dataset':\n",
    "        df_PL_all['finetuning_dataset_int'][i] = 0\n",
    "    elif finetuning_dataset == 'book_3chapters_dataset':\n",
    "        df_PL_all['finetuning_dataset_int'][i] = 1\n",
    "    else:\n",
    "        df_PL_all['finetuning_dataset_int'][i] = 2\n",
    "# if finetuning_quantized == 'f_base' then finetuning_quantized_int = 0 else finetuning_quantized_int = 1\n",
    "df_PL_all['finetuning_quantized_int'] = None\n",
    "for i, finetuning_quantized in enumerate(df_PL_all['finetuning_quantized']):\n",
    "    if finetuning_quantized == 'f_base':\n",
    "        df_PL_all['finetuning_quantized_int'][i] = 0\n",
    "    else:\n",
    "        df_PL_all['finetuning_quantized_int'][i] = 1\n",
    "# get df with only ['mode_int', 'model_int', 'quantized_int', 'dataset_int', 'temperature_int', 'finetuning_dataset_int', 'finetuning_quantized_int', 'lr', 'bs', 'mbs', 'mi'] columns\n",
    "df = df_PL_all[['model_int', 'quantized_int', 'finetuning_dataset_int', 'finetuning_quantized_int', 'lr', 'bs', 'mi', 'correct_responses']].copy()\n",
    "\n",
    "corr = df.corr()\n",
    "\n",
    "xticklabels = ['model', 'quantization', 'finetuning dataset', 'quantized finetuning', 'learning rate', 'batch size', 'iterations', 'accuracy']\n",
    "heatmap = sns.heatmap(df.corr(), annot=True, cmap='coolwarm', xticklabels=xticklabels, yticklabels=xticklabels, fmt='.2f', annot_kws={'size': 10})\n",
    "# Rotate x-axis labels\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "# Rotate y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
    "# Add title\n",
    "plt.title(\"Correlation Matrix of finetuning hyperparameters\")\n",
    "# Save the plot with tight layout\n",
    "plt.savefig('data/plots/correlation_matrix.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PL_all2 = df_PL_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PL_all = df_PL_all2.copy()\n",
    "partitions = ['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data', 'programming_languages']\n",
    "y_values = []\n",
    "for i, pl_all in enumerate(['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'structuring_data']):\n",
    "    tmp_values = df_PL_all[pl_all]\n",
    "    tmp_values = tmp_values.tolist()\n",
    "    if i > 0:\n",
    "        y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "    else:\n",
    "        y_values = tmp_values\n",
    "df_PL_all['All-PL'] = y_values\n",
    "df_PL_all['All-PL_accuracy'] = round(df_PL_all['All-PL'] / 82 * 100)\n",
    "\n",
    "y_values = []\n",
    "for i, pl_all in enumerate(['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'object_oriented_paradigm', 'control_structure', 'programming_languages']):\n",
    "    tmp_values = df_PL_all[pl_all]\n",
    "    tmp_values = tmp_values.tolist()\n",
    "    if i > 0:\n",
    "        y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "    else:\n",
    "        y_values = tmp_values\n",
    "df_PL_all['All-SD'] = y_values\n",
    "df_PL_all['All-SD_accuracy'] = round(df_PL_all['All-SD'] / 132 * 100)\n",
    "\n",
    "y_values = []\n",
    "for i, pl_all in enumerate(['functional_programming', 'algorithms', 'fundations', 'abstract_machines', 'memory_management', 'names_and_the_environment', 'describing_a_programming_language', 'control_structure', 'programming_languages']):\n",
    "    tmp_values = df_PL_all[pl_all]\n",
    "    tmp_values = tmp_values.tolist()\n",
    "    if i > 0:\n",
    "        y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "    else:\n",
    "        y_values = tmp_values\n",
    "df_PL_all['All-SD-OOP'] = y_values\n",
    "df_PL_all['All-SD-OOP_accuracy'] = round(df_PL_all['All-SD-OOP'] / 121 * 100)\n",
    "\n",
    "y_values = []\n",
    "for i, pl_all in enumerate(['object_oriented_paradigm', 'structuring_data']):\n",
    "    tmp_values = df_PL_all[pl_all]\n",
    "    tmp_values = tmp_values.tolist()\n",
    "    if i > 0:\n",
    "        y_values = [tmp_values[i] + y_values[i] for i in range(len(tmp_values))]\n",
    "    else:\n",
    "        y_values = tmp_values\n",
    "df_PL_all['SDandOOP'] = y_values\n",
    "df_PL_all['SDandOOP_accuracy'] = round(df_PL_all['SDandOOP'] / 41 * 100)\n",
    "\n",
    "# correlation matrix of df_PL_all for PL_vs_all\n",
    "df = df_PL_all[['model_int', 'quantized_int', 'finetuning_dataset_int', 'finetuning_quantized_int', 'lr', 'bs', 'mi', 'accuracy', 'programming_languages_accuracy', 'All-PL_accuracy', 'structuring_data_accuracy', 'All-SD_accuracy', 'SDandOOP_accuracy', 'All-SD-OOP_accuracy']].copy()\n",
    "\n",
    "df_corr = df.corr()\n",
    "subset_columns_x = ['model_int', 'quantized_int', 'finetuning_dataset_int', 'finetuning_quantized_int', 'lr', 'bs', 'mi']\n",
    "subset_columns_y = ['accuracy', 'programming_languages_accuracy', 'All-PL_accuracy', 'structuring_data_accuracy', 'All-SD_accuracy', 'SDandOOP_accuracy', 'All-SD-OOP_accuracy']\n",
    "subset_corr = df_corr.loc[subset_columns_y, subset_columns_x]\n",
    "\n",
    "\"\"\" df_pivot = df_PL_all.pivot(index='fine_tuning_dataset', columns=['accuracy', 'programming_languages_accuracy', 'All-PL_accuracy', 'structuring_data_accuracy', 'All-SD_accuracy', 'SDandOOP_accuracy', 'All-SD-OOP_accuracy']) \"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5)) \n",
    "xticklabels = ['model', 'quantization', 'finetuning dataset', 'quantized finetuning', 'learning rate', 'batch size', 'iterations']\n",
    "yticklabels = ['All MCQs accuracy', 'PL accuracy', '(All - PL) accuracy', 'SD accuracy', '(All - SD) accuracy', 'SD and OOP accuracy', '(All - SD - OOP) accuracy']\n",
    "heatmap = sns.heatmap(subset_corr, annot=True, cmap='coolwarm', xticklabels=xticklabels, yticklabels=yticklabels, fmt='.2f', annot_kws={'size': 10}, ax=ax, vmin=-1, vmax=1)\n",
    "# Rotate x-axis labels\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "# Rotate y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
    "# Add title\n",
    "plt.title(\"Correlation of hyperparameters with partitions accuracy\")\n",
    "# Save the plot with tight layout\n",
    "plt.savefig('data/plots/correlation_matrix.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "\"\"\" fig2, ax2 = plt.subplots(figsize=(5,5))\n",
    "xticklabels = ['book_dataset', 'book_3chapters_dataset', 'book_1chapter_dataset']\n",
    "yticklabels = ['All MCQs accuracy', 'PL accuracy', '(All - PL) accuracy', 'SD accuracy', '(All - SD) accuracy', 'SD and OOP accuracy', '(All - SD - OOP) accuracy']\n",
    "heatmap = sns.heatmap(df_pivot, annot=True, cmap='coolwarm', xticklabels=xticklabels, yticklabels=yticklabels, fmt='.2f', annot_kws={'size': 10}, ax=ax2, vmin=-1, vmax=1)\n",
    "# Rotate x-axis labels\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "# Rotate y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, ha='right')\n",
    "# Add title\n",
    "plt.title(\"Correlation of fine-tuning datasets with partitions accuracy\")\n",
    "# Save the plot with tight layout\n",
    "plt.savefig('data/plots/correlation_matrix.png', bbox_inches='tight', dpi=300) \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
